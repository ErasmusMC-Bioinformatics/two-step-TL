{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,cross_val_score,StratifiedKFold,KFold\n",
    "from sklearn.feature_selection import SelectKBest,f_classif,SelectFdr\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize,RobustScaler,StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from lifelines import CoxPHFitter\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import glorot_uniform,RandomUniform,Constant\n",
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read GSE expression data, with same genes as GDSC\n",
    "impress1 = pd.read_csv(\"cellNorm22cpm_input.csv\")\n",
    "impress1 = impress1.set_index(['Unnamed: 0'])\n",
    "impress1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read auc\n",
    "auc = pd.read_csv(\"tmz paper_screening data and survival data_IN_12Nov21.csv\")\n",
    "auc = auc.set_index(['GS.number'])\n",
    "auc = auc.reindex(impress1.index)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear transform it to [0,10]\n",
    "auc_norm = auc.AUC\n",
    "auc_norm = (auc_norm - auc_norm.max())/(auc_norm.max() - auc_norm.min())+1\n",
    "auc_norm = auc_norm*10\n",
    "plt.hist(auc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss function\n",
    "def plt_loss(train_loss,validate_loss,fold_no):\n",
    "    plt.figure(figsize=(8, 8))=\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(validate_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a basic deep learning model\n",
    "def create_model(activation1 = \"sigmoid\",activation2 = \"softplus\",l2 = 0.0001,l1=0.0001,opt = tf.keras.optimizers.Adam(learning_rate= 0.0001)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1000,activation = activation1,input_shape=(17419,), #14298, 20076\n",
    "                    kernel_regularizer =regularizers.l2(l2),\n",
    "                    activity_regularizer = regularizers.l1(l1),\n",
    "                    kernel_initializer = RandomUniform(seed = 999)\n",
    "                    # weights = [pre_model.layers[0].get_weights()[0],pre_model.layers[0].get_weights()[1]])\n",
    "                   )\n",
    "             )\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(100, activation = activation2,\n",
    "                    kernel_initializer = RandomUniform(seed = 999)\n",
    "                    #weights = [pre_model.layers[2].get_weights()[0],pre_model.layers[2].get_weights()[1]]\n",
    "                   )\n",
    "             )\n",
    "                    \n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1, activation= activation2, kernel_initializer = RandomUniform(seed = 999)))\n",
    "        \n",
    "    model.compile(loss='mse',\n",
    "                  optimizer = opt,\n",
    "                  metrics=['mean_absolute_error'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use the same partition on the dataset for diffrent experiment to ensure a fair evaluation\n",
    "train_test_index = pd.read_csv(\"train_test_index_sort.txt\", sep=\"[\", header=None)\n",
    "\n",
    "line = 0\n",
    "\n",
    "train_index = [0] * 10\n",
    "test_index = [0] * 10\n",
    "\n",
    "for seed in range(0,10):\n",
    "    \n",
    "    train_index[seed] = [0] * 3\n",
    "    test_index[seed] = [0] * 3\n",
    "    \n",
    "    for fold in range(0,3):\n",
    "        \n",
    "        # get index train\n",
    "        train_index[seed][fold] = train_test_index[1][line].split()\n",
    "        # string to int\n",
    "        train_index[seed][fold] = [eval(i) for i in train_index[seed][fold]]\n",
    "        \n",
    "                # get index train\n",
    "        test_index[seed][fold] = train_test_index[2][line].split()\n",
    "        # string to int\n",
    "        test_index[seed][fold] = [eval(i) for i in test_index[seed][fold]]\n",
    "        \n",
    "        line += 1\n",
    "\n",
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "Standard = StandardScaler()\n",
    "\n",
    "Robust = RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### 3-fold CV ####\n",
    "\n",
    "# initialize lists of results\n",
    "overall_cor_res = []\n",
    "corr_list= []\n",
    "\n",
    "\n",
    "# repeat 10 times with different seeds of partition\n",
    "for k in range(0,10):\n",
    "    \n",
    "    exp_train = [0]*3\n",
    "    exp_test = [0]*3\n",
    "    auc_train = [0]*3\n",
    "    auc_test = [0]*3\n",
    "    pred_res = []\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    mse = []\n",
    "    val_mse = []\n",
    "    \n",
    "    # 3 fold CV\n",
    "    for fold_no in range(0,3):\n",
    "    \n",
    "        # split dataset\n",
    "        exp_train[fold_no], exp_test[fold_no] = impress1.iloc[train_index[k][fold_no],:], impress1.iloc[test_index[k][fold_no],:]\n",
    "        auc_train[fold_no], auc_test[fold_no] = auc_norm[train_index[k][fold_no]], auc_norm[test_index[k][fold_no]]\n",
    "    \n",
    "    \n",
    "        # normalize\n",
    "        exp_train[fold_no] = Standard.fit_transform(exp_train[fold_no])\n",
    "        exp_test[fold_no] = Standard.fit_transform(exp_test[fold_no])\n",
    "    \n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {(fold_no+1)}, seed {(k+1)} ...')\n",
    "    \n",
    "        # Create a basic model instance\n",
    "        pred_model = create_model(l2 = 0.0001,l1=0.0001,opt = tf.keras.optimizers.Adam(learning_rate= 0.001))\n",
    "\n",
    "                \n",
    "\n",
    "        refine_model = pred_model.fit(x=exp_train[fold_no], y=auc_train[fold_no], epochs=50, batch_size=32,\n",
    "                                      validation_data = (exp_test[fold_no],auc_test[fold_no].to_numpy())) \n",
    "    \n",
    "        # predict and evaluate\n",
    "        pred = pred_model.predict(exp_test[fold_no])\n",
    "        pred = pd.DataFrame(pred)\n",
    "        pred_res.append(pred)\n",
    "        test = auc_test[fold_no].reset_index(drop = True)\n",
    "       \n",
    "    \n",
    "        # calculate Spearman's correlation\n",
    "        corr, _ = spearmanr(test, pred[0])\n",
    "        print('Spearman correlation: %.3f' % corr)\n",
    "        corr_list.append(corr)\n",
    "    \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.scatter(test,pred[0])\n",
    "        plt.plot([0, 10], [0, 10], 'k-', lw=2)\n",
    "    \n",
    "        # plot loss train and validate\n",
    "        loss.append(refine_model.history['loss'])\n",
    "        val_loss.append(refine_model.history['val_loss'])\n",
    "        plt_loss(loss[fold_no],val_loss[fold_no],fold_no+1)\n",
    "    \n",
    "        # plot acc train and validate\n",
    "        mse.append(refine_model.history['mean_absolute_error'])\n",
    "        val_mse.append(refine_model.history['val_mean_absolute_error'])\n",
    "        plt_loss(mse[fold_no],val_mse[fold_no],fold_no+1)\n",
    "        \n",
    "    # test_all\n",
    "    test_all = np.concatenate([auc_test[0],auc_test[1],auc_test[2]])#,auc_test[3],auc_test[4]\n",
    "    # pred_all \n",
    "    pred_all = np.concatenate([pred_res[0],pred_res[1],pred_res[2]])#,pred_res[3],pred_res[4]\n",
    "    overall_cor, _ = spearmanr(test_all, pred_all)\n",
    "    overall_cor_res.append(overall_cor)\n",
    "    print('Overall spearman correlation: %.3f' % overall_cor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### use mae as the loss function ####\n",
    "\n",
    "# normalize\n",
    "impress_std = Standard.fit_transform(impress1)\n",
    "    \n",
    "# Create a basic model instance\n",
    "pred_model = create_model(l2 = 0.0001,l1=0.0001,opt = tf.keras.optimizers.Adam(lr = 0.001))#\n",
    "  \n",
    "refine_model = pred_model.fit(x=impress_std, y=auc_norm, epochs=50, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_model.save_weights(\"impress_model_oxa_tmz_GDSC_impress_new.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
