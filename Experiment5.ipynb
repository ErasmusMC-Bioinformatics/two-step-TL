{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,cross_val_score,StratifiedKFold,KFold\n",
    "from sklearn.feature_selection import SelectKBest,f_classif,SelectFdr\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import normalize,RobustScaler,StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from lifelines import CoxPHFitter\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import glorot_uniform,RandomUniform,Constant\n",
    "from scipy.stats import spearmanr\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GDSC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the genes from GDSC\n",
    "genes = pd.read_csv(\"genes_GDSC_oxa.csv\")\n",
    "genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPRESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load GSE data expression\n",
    "impress = pd.read_csv(\"cellNorm22cpm_input.csv\")\n",
    "impress = impress.set_index(['Unnamed: 0'])\n",
    "impress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make the order of genes consistent to GDSC\n",
    "impress = impress.reindex(columns = genes[\"Unnamed: 0.1\"])\n",
    "impress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load AUC\n",
    "auc = pd.read_csv(\"tmz paper_screening data and survival data_IN_12Nov21.csv\")\n",
    "auc = auc.set_index(['GS.number'])\n",
    "auc = auc.reindex(impress.index)\n",
    "auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC distribution\n",
    "plt.hist(auc.AUC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear transform AUC into range [0,10]\n",
    "auc_norm = auc.AUC\n",
    "auc_norm = (auc_norm - auc_norm.max())/(auc_norm.max() - auc_norm.min())+1\n",
    "auc_norm = auc_norm*10\n",
    "plt.hist(auc_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a basic DL model\n",
    "\n",
    "seed_num = 1000\n",
    "init = RandomUniform(seed = seed_num)\n",
    "\n",
    "def create_model(activation1 = \"sigmoid\",activation2=\"softplus\",l2 = 0.001,l1=0.001,opt = tf.keras.optimizers.Adam(learning_rate= 0.0001)):\n",
    "     \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1000,activation= activation1,input_shape=(10232,),\n",
    "                    kernel_regularizer=regularizers.l2(l2),\n",
    "                    activity_regularizer=regularizers.l1(l1),\n",
    "                    kernel_initializer= init))       \n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(100, activation=activation2,kernel_initializer= init))\n",
    "                    \n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1, activation= activation2))\n",
    "        \n",
    "    model.compile(loss='mean_squared_error',optimizer = opt,metrics=['mae']) #SGD\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss function\n",
    "def plt_loss(train_loss,validate_loss,fold_no):\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    #plt.subplot(5, 1, fold_no)\n",
    "    plt.plot(train_loss, label='Training Loss')\n",
    "    plt.plot(validate_loss, label='Validation Loss')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.ylabel('Loss')\n",
    "    #plt.ylim([0,0.6])\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained HGCC weights\n",
    "pre_model = create_model()\n",
    "pre_model.load_weights(\"HGCC_model_only.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize and predict GSE AUC with the pre-trained weights without fine-tune\n",
    "Standard = StandardScaler()\n",
    "impress_norm = Standard.fit_transform(impress)\n",
    "pred_auc = pre_model.predict(impress_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation\n",
    "spearmanr(auc_norm,pred_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DL model and load pre-trained weights on the first layer\n",
    "def create_model2(activation1 = \"sigmoid\",activation2 = \"softplus\",l2 = 0.0001,l1=0.0001,opt = tf.keras.optimizers.Adam(learning_rate= 0.0001)):\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(1000,activation= activation1,input_shape=(10232,),\n",
    "                    kernel_regularizer=regularizers.l2(l2),\n",
    "                    activity_regularizer=regularizers.l1(l1),\n",
    "                    weights = [pre_model.layers[0].get_weights()[0],pre_model.layers[0].get_weights()[1]]))            \n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Dense(100, activation=activation2,\n",
    "                    kernel_initializer=init\n",
    "                   )\n",
    "             )\n",
    "                    \n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Dense(1, activation= activation2, kernel_initializer=init))\n",
    "        \n",
    "    model.compile(loss='mse',\n",
    "                  optimizer = opt,\n",
    "                  metrics=['mean_absolute_error'])\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the same partition on the dataset to ensure a fair evaluation\n",
    "train_test_index = pd.read_csv(\"train_test_index_sort.txt\", sep=\"[\", header=None)\n",
    "\n",
    "line = 0\n",
    "\n",
    "train_index = [0] * 10\n",
    "test_index = [0] * 10\n",
    "\n",
    "for seed in range(0,10):\n",
    "    \n",
    "    train_index[seed] = [0] * 3\n",
    "    test_index[seed] = [0] * 3\n",
    "    \n",
    "    for fold in range(0,3):\n",
    "        \n",
    "        # get index train\n",
    "        train_index[seed][fold] = train_test_index[1][line].split()\n",
    "        # string to int\n",
    "        train_index[seed][fold] = [eval(i) for i in train_index[seed][fold]]\n",
    "        \n",
    "                # get index train\n",
    "        test_index[seed][fold] = train_test_index[2][line].split()\n",
    "        # string to int\n",
    "        test_index[seed][fold] = [eval(i) for i in test_index[seed][fold]]\n",
    "        \n",
    "        line += 1\n",
    "\n",
    "train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##### 3-fold CV to evaluate the model performance ####\n",
    "\n",
    "# initiate the list of results\n",
    "overall_cor_res = []\n",
    "\n",
    "# 10 partitions\n",
    "for k in range(0,10):\n",
    "    \n",
    "    exp_train = [0]*3\n",
    "    exp_test = [0]*3\n",
    "    auc_train = [0]*3\n",
    "    auc_test = [0]*3\n",
    "    pred_res = []\n",
    "    # plot loss\n",
    "    loss = []\n",
    "    val_loss = []\n",
    "    mse = []\n",
    "    val_mse = []\n",
    "    \n",
    "    # 3-fold CV\n",
    "    for fold_no in range(0,3):\n",
    "    \n",
    "        # split dataset\n",
    "        exp_train[fold_no], exp_test[fold_no] = impress.iloc[train_index[k][fold_no],:], impress.iloc[test_index[k][fold_no],:]\n",
    "        auc_train[fold_no], auc_test[fold_no] = auc_norm[train_index[k][fold_no]], auc_norm[test_index[k][fold_no]]\n",
    "    \n",
    "    \n",
    "        # normalize\n",
    "        exp_train[fold_no] = Standard.fit_transform(exp_train[fold_no])\n",
    "        exp_test[fold_no] = Standard.fit_transform(exp_test[fold_no])\n",
    "    \n",
    "        # Generate a print\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {(fold_no+1)}, seed {(k+1)} ...')\n",
    "    \n",
    "        # Create a basic model instance\n",
    "        pred_model = create_model2(l2 = 0.0001,l1=0.0001,opt = tf.keras.optimizers.Adam(lr = 0.0001))\n",
    "    \n",
    "        refine_model = pred_model.fit(x=exp_train[fold_no], y=auc_train[fold_no], epochs=50, batch_size=32,\n",
    "                                  validation_data=(exp_test[fold_no],auc_test[fold_no])\n",
    "                                 )\n",
    "        \n",
    "\n",
    "    \n",
    "        # predict and evaluate\n",
    "        pred = pred_model.predict(exp_test[fold_no])\n",
    "        pred = pd.DataFrame(pred)\n",
    "        pred_res.append(pred)\n",
    "        test = auc_test[fold_no].reset_index(drop = True)\n",
    "        \n",
    "    \n",
    "        # calculate Spearman's correlation\n",
    "        corr, _ = spearmanr(test, pred[0])\n",
    "        print('Spearman correlation: %.3f' % corr)\n",
    "    \n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.scatter(test,pred[0])\n",
    "        plt.plot([0, 10], [0, 10], 'k-', lw=2)\n",
    "    \n",
    "        # plot loss train and validate\n",
    "        loss.append(refine_model.history['loss'])\n",
    "        val_loss.append(refine_model.history['val_loss'])\n",
    "        plt_loss(loss[fold_no],val_loss[fold_no],fold_no+1)\n",
    "    \n",
    "        # plot acc train and validate\n",
    "        mse.append(refine_model.history['mean_absolute_error'])\n",
    "        val_mse.append(refine_model.history['val_mean_absolute_error'])\n",
    "        plt_loss(mse[fold_no],val_mse[fold_no],fold_no+1)\n",
    "\n",
    "\n",
    "    \n",
    "    # test_all\n",
    "    test_all = np.concatenate([auc_test[0],auc_test[1],auc_test[2]]\n",
    "    # pred_all \n",
    "    pred_all = np.concatenate([pred_res[0],pred_res[1],pred_res[2]])\n",
    "    overall_cor, _ = spearmanr(test_all, pred_all)\n",
    "    overall_cor_res.append(overall_cor)\n",
    "    print('Overall spearman correlation: %.3f' % overall_cor)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
